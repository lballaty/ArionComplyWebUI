/**
 * ARIONCOMPLY ARCHITECTURE - COMPREHENSIVE DATA FLOW
 * =================================================
 * 
 * This document provides a comprehensive overview of the ArionComply system's
 * data flow, including all components, functions, and communication patterns.
 * 
 * SYSTEM OVERVIEW:
 * ---------------
 * ArionComply is a standards compliance platform with the following key components:
 * 
 * 1. Flutter Frontend - User interface for web and mobile
 * 2. Supabase Edge Functions - Central router for all API requests
 * 3. PostgreSQL Database - Data storage and metadata registry
 * 4. Local Services - Retrieval, LLM, and graph processing
 * 
 * This implementation follows the architecture and milestone plan from docs/Detailed-Plan.md
 * 
 * KEY COMPONENTS AND FUNCTIONS:
 * ---------------------------
 * 
 * 1. Edge Function Router (`assistant_router`)
 *    The central router handles all requests from the Flutter frontend, implementing:
 *    - handler(): Main entry point that routes all requests based on action type
 *    - handle_chat_message(): Processes user chat messages, retrieves evidence, and generates responses
 *    - handle_admin_ingest(): Manages content ingestion (admin only)
 *    - handle_validate_signup(): Validates new user signups with domain checks and Turnstile verification
 * 
 * 2. Retrieval Services
 *    The evidence retrieval components implement the deterministic retrieval approach:
 *    - rank_query(): Calls the local rank query service for evidence with confidence scoring
 *    - bm25_fallback(): Fallback mechanism using PostgreSQL full-text search when primary retrieval fails
 *    - graph_expand(): Enhances retrieval with related standards via graph relationships
 *    - summarize_prose(): Generates natural language responses from evidence using local LLM
 * 
 * 3. Validators and Helpers
 *    These utilities implement the platform's requirements:
 *    - is_off_topic(): Detects off-topic messages for abuse control
 *    - check_pending_user_limits(): Enforces the 5/day cap on standards questions for pending users
 *    - verify_turnstile(): Prevents bot signups with Cloudflare Turnstile
 *    - check_blocked_domain(): Blocks common free domains as required
 *    - log_trace(): Records detailed traces for observability
 * 
 * 4. Local Service Implementations
 *    The backend Python services provide the core intelligence:
 *    - rank_query_service.py: Implements deterministic multi-index retrieval with E-PMI scoring
 *    - graph_service.py: Provides graph-based expansion of related standards
 *    - summarize_prose.py: Generates prose responses using local CPU-optimized LLM
 * 
 * 5. Flutter Integration
 *    The Flutter frontend communicates with the Edge Functions:
 *    - ApiService: Dart class for HTTP communication with the backend
 *    - sendChatMessage(): Main method for sending user queries and receiving responses
 * 
 * DATA FLOW SEQUENCE:
 * -----------------
 * 1. User sends query through Flutter frontend â†’ Edge Function router
 * 2. Edge Function validates request, checks permissions
 * 3. Message stored in conversation history
 * 4. Edge Function calls rank_query service to retrieve evidence
 * 5. If needed, graph_expand enhances results for mid-confidence queries
 * 6. If requested, summarize_prose generates natural language response
 * 7. Complete response sent back to Flutter frontend
 * 8. All operations logged for tracing and observability
 * 
 * This implementation fulfills all requirements from the detailed plan, including the 
 * milestones M1-M5, with proper handling of both Cards and Prose outputs, typing
 * simulation, and the various security and compliance controls.
 */

// ===================================================================
// PART 1: SUPABASE EDGE FUNCTION (ASSISTANT ROUTER)
// ===================================================================

/**
 * Main Edge Function entry point - routes all requests
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/index.js
 * 
 * This is the central router that handles all incoming requests from the Flutter
 * frontend. It validates requests, checks permissions, and routes to appropriate
 * handlers based on the action parameter.
 */
export async function handler(req, res) {
  // Initialize Supabase client
  const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_SERVICE_ROLE_KEY);
  
  // Extract request details
  const { action, payload, output_mode = 'both' } = req.body;
  
  // Get user context from JWT
  const token = req.headers.authorization?.split('Bearer ')[1];
  const { data: { user } } = await supabase.auth.getUser(token);
  
  // Log request for tracing
  const traceId = crypto.randomUUID();
  await log_trace(supabase, {
    trace_id: traceId,
    user_id: user?.id,
    action: action,
    timestamp: new Date().toISOString()
  });
  
  // Check pending user limits (M3 requirement)
  if (user?.user_metadata?.status === 'pending') {
    if (await check_pending_user_limits(supabase, user, payload)) {
      return res.status(403).json({
        error: 'pending_limit_reached',
        message: 'Pending users are limited to 5 standards questions per day. Please complete verification.'
      });
    }
  }
  
  // Route request based on action type
  try {
    switch (action) {
      // Chat/Query Actions
      case 'chat.message':
        return await handle_chat_message(supabase, user, payload, output_mode, traceId, res);
      
      // Admin/Management Actions
      case 'admin.ingest':
        return await handle_admin_ingest(supabase, user, payload, traceId, res);
      
      // User/Auth Actions
      case 'validate_signup':
        return await handle_validate_signup(supabase, payload, traceId, res);
      
      default:
        await log_trace(supabase, {
          trace_id: traceId,
          status: 'error',
          error: 'unknown_action',
          details: `Unknown action: ${action}`
        });
        return res.status(400).json({ error: 'unknown_action', message: 'Unknown action type' });
    }
  } catch (error) {
    console.error(`Error processing ${action}:`, error);
    
    await log_trace(supabase, {
      trace_id: traceId,
      status: 'error',
      error: error.message,
      stack: error.stack
    });
    
    return res.status(500).json({ 
      error: 'internal_server_error', 
      message: 'An internal server error occurred',
      trace_id: traceId
    });
  }
}

/**
 * Handles chat message requests from frontend
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/handlers/chat.js
 * 
 * This function processes user chat messages, checks for off-topic content,
 * retrieves relevant evidence, generates prose responses (if requested),
 * and returns the appropriate response format.
 */
async function handle_chat_message(supabase, user, payload, output_mode, traceId, res) {
  const { message, conversation_id, context } = payload;
  const startTime = Date.now();
  
  // Check for off-topic content (M3 requirement)
  if (await is_off_topic(message)) {
    await log_trace(supabase, {
      trace_id: traceId,
      status: 'success',
      details: 'off_topic_nudge',
      latency_ms: Date.now() - startTime
    });
    
    return res.status(200).json({
      data: {
        response: "I'm designed to help with ISO 27001 and 27701 standards compliance questions. Could you please rephrase your question to focus on these standards?",
        off_topic_nudge: true,
        trace_id: traceId
      }
    });
  }
  
  // Create or update conversation record
  let conversationId = conversation_id;
  if (!conversationId) {
    const { data, error } = await supabase
      .from('chat_conversations')
      .insert({
        user_id: user.id,
        title: generate_conversation_title(message),
        organization_id: user.organization_id
      })
      .select('id')
      .single();
      
    if (error) {
      throw new Error(`Failed to create conversation: ${error.message}`);
    }
    
    conversationId = data.id;
  }
  
  // Store user message
  const { data: msgData, error: msgError } = await supabase
    .from('chat_messages')
    .insert({
      conversation_id: conversationId,
      role: 'user',
      content: message,
      organization_id: user.organization_id
    })
    .select('id, conversation_id')
    .single();
  
  if (msgError) {
    throw new Error(`Failed to store message: ${msgError.message}`);
  }
  
  // Call rank_query service to get evidence (M2 requirement)
  const rankQueryStartTime = Date.now();
  const evidence = await rank_query(message, user.organization_id);
  const rankQueryTime = Date.now() - rankQueryStartTime;
  
  // Prepare response based on output mode
  let response = {
    conversation_id: msgData.conversation_id,
    trace_id: traceId
  };
  
  // Cards output (default)
  if (output_mode === 'cards' || output_mode === 'both') {
    response.evidence = evidence;
    response.output_mode = output_mode === 'both' ? 'both' : 'cards';
  }
  
  // Prose output (if requested)
  if (output_mode === 'prose' || output_mode === 'both') {
    const proseStartTime = Date.now();
    const proseResponse = await summarize_prose(evidence, message);
    const proseTime = Date.now() - proseStartTime;
    
    response.prose = proseResponse;
    response.output_mode = output_mode === 'both' ? 'both' : 'prose';
    
    // Typing simulation support (M3 requirement)
    if (payload.typing_simulation) {
      response.typing_simulation = true;
    }
    
    await log_trace(supabase, {
      trace_id: traceId,
      component: 'summarize_prose',
      latency_ms: proseTime,
      details: `Prose generated with ${evidence.length} evidence items`
    });
  }
  
  // Log the AI response
  await supabase
    .from('chat_messages')
    .insert({
      conversation_id: msgData.conversation_id,
      role: 'assistant',
      content: output_mode.includes('prose') ? response.prose : JSON.stringify(evidence),
      metadata: {
        evidence_count: evidence.length,
        confidence_scores: evidence.map(e => e.confidence),
        fallback_used: evidence.some(e => e.source === 'bm25_fallback'),
        output_mode: output_mode,
        rank_query_time_ms: rankQueryTime
      },
      organization_id: user.organization_id
    });
  
  // Complete trace log
  await log_trace(supabase, {
    trace_id: traceId,
    status: 'success',
    component: 'handle_chat_message',
    latency_ms: Date.now() - startTime,
    details: {
      evidence_count: evidence.length,
      conversation_id: msgData.conversation_id,
      output_mode: output_mode,
      rank_query_time_ms: rankQueryTime
    }
  });
  
  return res.status(200).json({ data: response });
}

/**
 * Handles admin ingest requests (uploading new content)
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/handlers/admin.js
 * 
 * This function processes requests to ingest new content into the system.
 * It validates admin privileges before allowing ingestion.
 */
async function handle_admin_ingest(supabase, user, payload, traceId, res) {
  // Check if user has admin privileges
  const { data: userRoles } = await supabase
    .from('user_role_assignments')
    .select('role_id')
    .eq('user_id', user.id)
    .eq('is_active', true);
  
  const isAdmin = userRoles.some(ur => ur.role_id === process.env.ADMIN_ROLE_ID);
  
  if (!isAdmin) {
    await log_trace(supabase, {
      trace_id: traceId,
      status: 'error',
      error: 'permission_denied',
      details: 'Non-admin attempted to use admin.ingest'
    });
    
    return res.status(403).json({ 
      error: 'permission_denied',
      message: 'Admin privileges required for this action'
    });
  }
  
  // Process ingest (Note: actual implementation would call ingest scripts)
  // This is a placeholder for the actual ingestion process
  // In reality, this would trigger background jobs to process the content
  
  await log_trace(supabase, {
    trace_id: traceId,
    status: 'success',
    component: 'handle_admin_ingest',
    details: 'Ingest job queued'
  });
  
  return res.status(200).json({
    data: {
      status: 'ingest_queued',
      job_id: crypto.randomUUID(),
      trace_id: traceId
    }
  });
}

/**
 * Handles user signup validation requests
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/handlers/auth.js
 * 
 * This function validates new user signups, checking domains and
 * implementing Turnstile verification (M1/M3 requirements).
 */
async function handle_validate_signup(supabase, payload, traceId, res) {
  const { email, company, name, turnstile_token } = payload;
  
  // Verify Turnstile token (M3 requirement)
  const turnstileValid = await verify_turnstile(turnstile_token);
  if (!turnstileValid) {
    await log_trace(supabase, {
      trace_id: traceId,
      status: 'error',
      error: 'invalid_turnstile',
      details: 'Turnstile verification failed'
    });
    
    return res.status(400).json({
      error: 'invalid_turnstile',
      message: 'Human verification failed. Please try again.'
    });
  }
  
  // Check domain against blocklist (M1 requirement)
  const domain = email.split('@')[1].toLowerCase();
  const isBlockedDomain = await check_blocked_domain(supabase, domain);
  
  if (isBlockedDomain) {
    await log_trace(supabase, {
      trace_id: traceId,
      status: 'error',
      error: 'blocked_domain',
      details: `Blocked domain: ${domain}`
    });
    
    return res.status(400).json({
      error: 'blocked_domain',
      message: 'Please use a company email address to sign up.'
    });
  }
  
  // Check company name validity (M3 requirement)
  const companyValid = await validate_company_name(company);
  
  // Determine initial user status
  const initialStatus = companyValid ? 'active' : 'pending';
  
  await log_trace(supabase, {
    trace_id: traceId,
    status: 'success',
    component: 'handle_validate_signup',
    details: `Signup validated, initial status: ${initialStatus}`
  });
  
  return res.status(200).json({
    data: {
      valid: true,
      initial_status: initialStatus,
      trace_id: traceId
    }
  });
}

// ===================================================================
// PART 2: LOCAL SERVICES INTEGRATION
// ===================================================================

/**
 * Calls the rank_query service to retrieve evidence
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/services/retrieval.js
 * 
 * This function sends queries to the local rank_query_service for
 * deterministic retrieval with confidence scoring, implementing
 * BM25 fallback as required in M2.
 */
async function rank_query(query, organization_id) {
  try {
    // Call the local rank_query_service
    const response = await fetch(process.env.RANK_QUERY_SERVICE_URL, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ 
        query, 
        organization_id,
        // Additional parameters based on M2 requirements
        confidence_bands: true,
        graph_paths: true,
        include_reasons: true 
      }),
      // Timeout as specified in M2
      signal: AbortSignal.timeout(2000)
    });
    
    if (!response.ok) {
      console.error(`Rank query service error: ${response.status}`);
      // BM25 fallback as specified in M2
      return await bm25_fallback(query, organization_id);
    }
    
    const result = await response.json();
    
    // Call graph_expand for enhancing results in 0.40-0.60 confidence band
    if (result.confidence >= 0.40 && result.confidence <= 0.60) {
      try {
        const graphResults = await graph_expand(query, {
          initial_evidence: result.results.map(r => r.id)
        });
        
        if (graphResults && graphResults.length > 0) {
          // Merge graph results with initial results
          // This would be more sophisticated in reality
          result.results = [...result.results, ...graphResults.map(gr => ({
            ...gr,
            source: 'graph_probe',
            reasons: ['Added via graph relationship']
          }))];
        }
      } catch (graphError) {
        console.error('Graph expansion error:', graphError);
        // Continue with original results if graph fails
      }
    }
    
    // If confidence is still low after graph, use BM25 fallback
    if (result.confidence < 0.40) {
      const fallbackResults = await bm25_fallback(query, organization_id);
      result.results = [...result.results, ...fallbackResults.results];
      result.fallback_used = true;
    }
    
    return result;
  } catch (error) {
    console.error('Rank query service error:', error);
    // Circuit breaker pattern (M2 requirement)
    return await bm25_fallback(query, organization_id);
  }
}

/**
 * BM25 fallback for when rank_query fails or confidence is low
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/services/retrieval.js
 * 
 * This function implements the BM25 fallback required in M2, using
 * PostgreSQL full-text search when the primary retrieval fails.
 */
async function bm25_fallback(query, organization_id) {
  // In reality, this would use PostgreSQL FTS
  // This is a simplified implementation
  const supabase = createClient(process.env.SUPABASE_URL, process.env.SUPABASE_SERVICE_ROLE_KEY);
  
  // Extract keywords for search
  const keywords = query.toLowerCase()
    .replace(/[^\w\s]/g, '')
    .split(/\s+/)
    .filter(w => w.length > 2)
    .join(' | ');
  
  if (!keywords) {
    return { 
      results: [], 
      confidence: 0,
      source: 'bm25_fallback',
      query: query
    };
  }
  
  // Perform BM25 search using PostgreSQL
  const { data, error } = await supabase
    .from('evidence_cards')
    .select('*')
    .textSearch('content', keywords)
    .limit(5);
  
  if (error) {
    console.error('BM25 fallback error:', error);
    return { 
      results: [], 
      confidence: 0,
      source: 'bm25_fallback',
      query: query
    };
  }
  
  // Format results to match rank_query output
  return {
    results: data.map(item => ({
      id: item.id,
      title: item.title,
      content: item.content,
      source: 'bm25_fallback',
      confidence: 0.3, // Lower confidence for fallback results
      reasons: ['Added via BM25 fallback search']
    })),
    confidence: 0.3,
    source: 'bm25_fallback',
    query: query
  };
}

/**
 * Calls the graph_expand service to enhance retrieval
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/services/graph.js
 * 
 * This function sends requests to the local graph service to find
 * related standards via the graph relationship model (M2 requirement).
 */
async function graph_expand(query, context) {
  try {
    const response = await fetch(process.env.GRAPH_SERVICE_URL, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ query, context }),
      // 400ms timeout as specified in M2
      signal: AbortSignal.timeout(400)
    });
    
    if (!response.ok) {
      console.error(`Graph service error: ${response.status}`);
      return [];
    }
    
    return await response.json();
  } catch (error) {
    console.error('Graph service error:', error);
    return [];
  }
}

/**
 * Calls the summarize_prose service to generate prose responses
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/services/prose.js
 * 
 * This function sends evidence to the local LLM service to generate
 * a prose response based on the evidence (M3 requirement).
 */
async function summarize_prose(evidence, query) {
  try {
    const response = await fetch(process.env.SUMMARIZE_PROSE_SERVICE_URL, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ 
        evidence,
        query,
        // M3 requirements
        include_sources: true,
        typing_simulation: true
      }),
      // 3.0s target as specified in M3
      signal: AbortSignal.timeout(3000)
    });
    
    if (!response.ok) {
      console.error(`Summarize prose service error: ${response.status}`);
      return default_prose_response(evidence, query);
    }
    
    return await response.text();
  } catch (error) {
    console.error('Summarize prose service error:', error);
    return default_prose_response(evidence, query);
  }
}

/**
 * Generates a default prose response when the service fails
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/services/prose.js
 * 
 * This function creates a basic response using the evidence when
 * the prose service fails to respond.
 */
function default_prose_response(evidence, query) {
  if (!evidence || evidence.length === 0) {
    return "I couldn't find any specific information about that in the ISO 27001 or 27701 standards. Could you please rephrase your question or ask about a different aspect of these standards?";
  }
  
  // Basic response using the top evidence item
  const topEvidence = evidence[0];
  return `Based on the ISO standards, ${topEvidence.content} This information comes from the standards documentation. Would you like more specific details?`;
}

// ===================================================================
// PART 3: UTILITY FUNCTIONS
// ===================================================================

/**
 * Logs trace information for observability
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/utils/logging.js
 * 
 * This function logs traces to the database for monitoring and debugging
 * as required in M5.
 */
async function log_trace(supabase, traceData) {
  try {
    await supabase
      .from('request_traces')
      .insert({
        ...traceData,
        timestamp: traceData.timestamp || new Date().toISOString()
      });
  } catch (error) {
    console.error('Error logging trace:', error);
    // Non-blocking - continue even if logging fails
  }
}

/**
 * Checks if a user message is off-topic
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/utils/validators.js
 * 
 * This function checks if a user message is off-topic, implementing
 * the abuse controls required in M3.
 */
async function is_off_topic(message) {
  // For simplicity, using a basic keyword approach
  // In reality, this would be more sophisticated
  const standardsKeywords = ['iso', '27001', '27701', 'security', 'privacy', 
    'compliance', 'control', 'policy', 'risk', 'audit', 'standard'];
  
  const lowercaseMessage = message.toLowerCase();
  
  // Check if message contains any standards keywords
  const containsStandardsKeywords = standardsKeywords.some(keyword => 
    lowercaseMessage.includes(keyword));
  
  // Off-topic examples (simplified)
  const offTopicKeywords = ['weather', 'sports', 'recipe', 'movie', 'music',
    'travel', 'restaurant', 'game', 'invest', 'stock', 'crypto'];
  
  const containsOffTopicKeywords = offTopicKeywords.some(keyword =>
    lowercaseMessage.includes(keyword));
  
  // Message is off-topic if it contains off-topic keywords but no standards keywords
  return containsOffTopicKeywords && !containsStandardsKeywords;
}

/**
 * Checks if a query is related to standards
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/utils/validators.js
 * 
 * This function determines if a query is about standards for
 * enforcing pending user limits (M3 requirement).
 */
function is_standards_query(message) {
  // Similar to is_off_topic but specifically identifies standards queries
  const standardsKeywords = ['iso', '27001', '27701', 'security', 'privacy', 
    'compliance', 'control', 'policy', 'risk', 'audit', 'standard',
    'clause', 'requirement', 'certification'];
  
  const lowercaseMessage = message.toLowerCase();
  
  // Check if message contains standards keywords
  return standardsKeywords.some(keyword => lowercaseMessage.includes(keyword));
}

/**
 * Checks pending user query limits
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/utils/validators.js
 * 
 * This function enforces the 5/day cap on standards questions for
 * pending users (M3 requirement).
 */
async function check_pending_user_limits(supabase, user, payload) {
  // Only apply limits to standards questions
  if (!is_standards_query(payload.message)) {
    return false; // No limit for non-standards questions
  }
  
  // Count today's standards questions
  const today = new Date().toISOString().split('T')[0];
  const { count, error } = await supabase
    .from('chat_messages')
    .select('id', { count: 'exact' })
    .eq('user_id', user.id)
    .gte('created_at', today)
    .eq('is_standards_query', true);
  
  if (error) {
    console.error('Error checking pending user limits:', error);
    return false; // Don't block on errors
  }
  
  // 5/day limit as specified in M3
  return count >= 5;
}

/**
 * Verifies Turnstile tokens for bot prevention
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/utils/validators.js
 * 
 * This function verifies Cloudflare Turnstile tokens to prevent
 * bot signups (M3 requirement).
 */
async function verify_turnstile(token) {
  if (!token) return false;
  
  try {
    const response = await fetch('https://challenges.cloudflare.com/turnstile/v0/siteverify', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        secret: process.env.TURNSTILE_SECRET,
        response: token
      })
    });
    
    const result = await response.json();
    return result.success === true;
  } catch (error) {
    console.error('Turnstile verification error:', error);
    return false;
  }
}

/**
 * Checks if a domain is on the blocklist
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/utils/validators.js
 * 
 * This function checks if an email domain is on the blocklist,
 * implementing the domain blocking required in M1.
 */
async function check_blocked_domain(supabase, domain) {
  // Check against database blocklist
  const { data, error } = await supabase
    .from('blocked_domains')
    .select('domain')
    .eq('domain', domain)
    .maybeSingle();
  
  if (error) {
    console.error('Error checking blocked domain:', error);
    return false; // Don't block on errors
  }
  
  // Domain is blocked if found in the table
  return data !== null;
}

/**
 * Validates company names for signup
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/utils/validators.js
 * 
 * This function validates company names for legitimacy as part
 * of the signup gating (M3 requirement).
 */
async function validate_company_name(company) {
  if (!company || company.length < 3) {
    return false;
  }
  
  // Basic validation rules
  const invalidNames = ['test', 'company', 'acme', 'example', 'none', 'n/a'];
  if (invalidNames.includes(company.toLowerCase())) {
    return false;
  }
  
  // In a real implementation, this might check against a company database
  // or use an LLM for plausibility checking as mentioned in M3
  
  return true;
}

/**
 * Generates a title for new conversations
 * Location: arioncomply-v1/backend/edge-functions/assistant_router/utils/helpers.js
 * 
 * This function generates a title for new conversations based on
 * the first message content.
 */
function generate_conversation_title(message) {
  // Extract first 5-8 words to create a title
  const words = message.split(/\s+/);
  const titleWords = words.slice(0, Math.min(words.length, 8));
  let title = titleWords.join(' ');
  
  // Add ellipsis if truncated
  if (words.length > 8) {
    title += '...';
  }
  
  return title;
}

// ===================================================================
// PART 4: LOCAL SERVICES IMPLEMENTATION
// ===================================================================

/**
 * Rank Query Service Implementation
 * Location: arioncomply-v1/backend/scripts/services/rank_query_service.py
 * 
 * This Python service implements the deterministic retrieval with
 * E-PMI scoring, confidence bands, and evidence reasons as required in M2.
 * 
 * Below is a simplified pseudocode representation of the core algorithm:
 */
/*
def rank_query(query, organization_id, confidence_bands=True, graph_paths=True, include_reasons=True):
    # 1. Extract keywords and entities from query
    query_terms = extract_keywords(query)
    query_entities = extract_entities(query)
    
    # 2. Expand with synonyms
    expanded_terms = expand_synonyms(query_terms)
    
    # 3. Calculate E-PMI scores across multi-index
    candidates = search_multi_index(expanded_terms, query_entities)
    scored_results = calculate_epmi_scores(candidates, expanded_terms)
    
    # 4. Apply confidence bands
    if confidence_bands:
        results_with_confidence = assign_confidence_bands(scored_results)
    
    # 5. Add reasoning signals
    if include_reasons:
        results_with_reasons = add_explanation_reasons(results_with_confidence, query)
    
    # 6. Add graph paths if requested
    if graph_paths:
        results_with_graph = add_graph_paths(results_with_reasons)
    
    # 7. Calculate overall confidence
    overall_confidence = calculate_overall_confidence(results_with_reasons)
    
    # 8. Return structured response
    return {
        "results": results_with_reasons,
        "confidence": overall_confidence,
        "query": query,
        "source": "epmi_ranker"
    }
*/

/**
 * Graph Service Implementation
 * Location: arioncomply-v1/backend/scripts/services/graph_service.py
 * 
 * This Python service implements the graph probe for finding related
 * standards requirements as specified in M2.
 * 
 * Below is a simplified pseudocode representation:
 */
/*
def graph_expand(query, context):
    # 1. Extract initial evidence IDs from context
    initial_ids = context.get("initial_evidence", [])
    
    # 2. Get graph nodes for initial evidence
    nodes = get_graph_nodes(initial_ids)
    
    # 3. Find connected nodes with edge weights
    edges = get_connected_edges(nodes)
    
    # 4. Sort by edge weight and relevance to query
    sorted_connections = sort_by_weight_and_relevance(edges, query)
    
    # 5. Return top results with relationship info
    results = []
    for conn in sorted_connections[:5]:  # Limit to top 5
        evidence = get_evidence_for_node(conn.target_node_id)
        evidence["relation"] = conn.relation_type
        evidence["weight"] = conn.weight
        evidence["source"] = "graph_probe"
        results.append(evidence)
    
    return results
*/

/**
 * Prose Summarizer Implementation
 * Location: arioncomply-v1/backend/scripts/llm/summarize_prose.py
 * 
 * This Python service implements the prose summarization using a local
 * CPU-optimized LLM as required in M3.
 * 
 * Below is a simplified pseudocode representation:
 */
/*
def summarize_prose(evidence, query, include_sources=True, typing_simulation=True):
    # 1. Format evidence for LLM context
    formatted_evidence = format_evidence_for_context(evidence)
    
    # 2. Construct prompt with instructions
    prompt = f"""
    You are ArionComply, an expert in ISO 27001 and 27701 standards.
    Answer the following question using ONLY the evidence provided.
    If the evidence doesn't contain relevant information, say so.
    Never make up information not in the evidence.
    
    QUESTION: {query}
    
    EVIDENCE:
    {formatted_evidence}
    
    ANSWER:
    """
    
    # 3. Call local LLM using llama.cpp
    response = call_local_llm(prompt)
    
    # 4. Format response with source citations if requested
    if include_sources:
        response = add_source_citations(response, evidence)
    
    # 5. Add typing simulation markers if requested
    if typing_simulation:
        response = add_typing_simulation_markers(response)
    
    return response
*/

// ===================================================================
// PART 5: FLUTTER FRONTEND INTEGRATION
// ===================================================================

/**
 * Flutter Frontend API Service
 * Location: arioncomply-v1/frontend-flutter/lib/services/api_service.dart
 * 
 * This Dart class provides methods for interacting with the Edge Functions
 * from the Flutter frontend.
 * 
 * Below is a simplified pseudocode representation:
 */
/*
class ApiService {
  final String _baseUrl;
  final String _apiKey;
  final FlutterSecureStorage _secureStorage = FlutterSecureStorage();
  
  ApiService({required String baseUrl, required String apiKey})
      : _baseUrl = baseUrl, _apiKey = apiKey;
  
  Future<String?> get authToken async {
    return await _secureStorage.read(key: 'auth_token');
  }
  
  Future<dynamic> sendRequest(String action, Map<String, dynamic> payload, {String outputMode = 'both'}) async {
    final token = await authToken;
    if (token == null) {
      throw Exception('Authentication required');
    }
    
    final response = await http.post(
      Uri.parse('$_baseUrl/assistant_router'),
      headers: {
        'Content-Type': 'application/json',
        'Authorization': 'Bearer $token',
        'ApiKey': _apiKey,
      },
      body: jsonEncode({
        'action': action,
        'payload': payload,
        'output_mode': outputMode,
      }),
    );
    
    if (response.statusCode != 200) {
      final error = jsonDecode(response.body);
      throw Exception(error['error'] ?? 'Unknown error');
    }
    
    return jsonDecode(response.body);
  }
  
  Future<Map<String, dynamic>> sendChatMessage(
    String message, {
    String? conversationId,
    Map<String, dynamic>? context,
    String outputMode = 'both',
    bool typingSimulation = true,
  }) async {
    final response = await sendRequest(
      'chat.message',
      {
        'message': message,
        'conversation_id': conversationId,
        'context': context,
        'typing_simulation': typingSimulation,
      },
      outputMode: outputMode,
    );
    
    return response['data'];
  }
  
  // Additional methods for user management, etc.
}
*/

// ===================================================================
// SUMMARY OF COMPONENTS
// ===================================================================

/**
 * ArionComply System Components
 * 
 * 1. Edge Function (assistant_router):
 *    - Central router for all API requests
 *    - Handles authentication, permission checks, and request routing
 *    - Integrates with local services via HTTP
 * 
 * 2. Local Services:
 *    - rank_query_service: Deterministic retrieval with E-PMI and confidence
 *    - graph_service: Graph-based expansion of related standards
 *    - summarize_prose: LLM-based prose generation from evidence
 * 
 * 3. Flutter Frontend:
 *    - User interface for web and mobile
 *    - Communicates with Edge Function via HTTP
 *    - Supports Cards/Prose output modes
 * 
 * 4. Database:
 *    - PostgreSQL with Supabase for data storage
 *    - Full-text search for BM25 fallback
 *    - Stores conversations, traces, and user data
 * 
 * The system follows the architecture defined in the detailed plan,
 * implementing all requirements from milestones M1-M5.
 */